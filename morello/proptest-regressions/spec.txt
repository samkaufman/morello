# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 621b28a0003170be9222da23c41c090ec5e74a300b151cd6975afe99a0695d6e # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [1, 4, 3, 14, 4, 14, 4], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Standard { dim_order: [0, 1, 2, 3] }, vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Packed { dim_count: 4, strip_dim: 0, strip_size: 2 }, vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Standard { dim_order: [0, 1, 2, 3] }, vector_size: None }], false), Standard(MemVec([64, 1024, 32768, 1073741824])))
cc d5426c7bbcebdcc94c7ac335e850051746c583d940c99fee06766bd804c98a59 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 5, 3], dtype: Uint8 }, [TensorSpecAux { contig: 3, aligned: true, level: GL, layout: Standard { dim_order: [0, 1, 2] }, vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: GL, layout: Packed { dim_count: 3, strip_dim: 1, strip_size: 4 }, vector_size: None }], false), Standard(MemVec([5, 4, 5, 19])))
cc 447224448efccd63b4b9d2fe07ba7933ec0062b1ca30eba898c6466eda8376d7 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 3], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None), (0, Some(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(1, None), (0, None)]), vector_size: None }], false)
cc 77094c43ccba12f5f0a16f0597c2abf9a1a0d063b6b636cdfc5d0c4b1f8b00f4 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [2, 3, 1], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(1, None), (0, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: New([(0, None), (1, None)]), vector_size: None }], false), Standard(MemVec([4, 4, 9, 4])))
cc 086206919c1e3b52e6509d8ae98732239cc8975ce1bb7eb326331724186bcca5 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 1], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }], true)
cc 1776df2ad05dea8e23b1cd294aceb31a18345f5be19b7a66e11e90818a90ec08 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [3, 5, 2, 8, 4, 8, 4], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: New([(0, None), (2, None), (3, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (2, Some(2))]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None)]), vector_size: None }], false), Standard(MemVec([5, 9, 2, 24])))
cc ca9e4ca2bd3626671393aaff4300d5d86fd65e73f6c080aa2b27c90f387a9906 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [6, 2, 3, 4, 6, 1, 2], dtype: Uint32 }, [TensorSpecAux { contig: 4, aligned: false, level: GL, layout: New([(0, None), (2, None), (3, None), (1, None), (3, Some(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: VRF, layout: New([(0, None), (2, None), (3, None), (1, None), (0, Some(2))]), vector_size: Some(16) }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: New([(0, None), (2, None), (3, None), (1, None), (0, Some(2))]), vector_size: Some(16) }], true), Standard(MemVec([4, 1, 11, 19])))
cc 738ff6c91fce386119abb1ccef46e4f7058a7f331660231e41a37b6d2dfe6115 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 4, 1], dtype: Uint32 }, [TensorSpecAux { contig: 4, aligned: true, level: RF, layout: New([(0, None), (1, None), (2, None), (0, Some(3))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (1, Some(2))]), vector_size: None }], false), Standard(MemVec([4, 1, 1, 7])))
cc b6c7d507517cf04edab95cde53e6436709ccde7ff0a139a76a92753c08a5c0c1 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [2, 8, 1], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: New([(0, None), (1, None), (0, Some(2))]), vector_size: None }], false)
cc 85ecfac179f4e3e8d334f2d8d820224a4620d1ec7ad2bdf338306efde4636009 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [7, 4, 1, 3, 1, 3, 1], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: New([(0, None), (1, None), (2, None), (3, None)]), vector_size: None }, TensorSpecAux { contig: 5, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (2, Some(3))]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (0, Some(7))]), vector_size: None }], false)
cc 92f95d4f0b88593df4096072665f0ada65b9d6ba7dcdf7527ffbd07785af5605 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 2], dtypes: [Uint16] }, [TensorSpecAux { contig: 2, aligned: true, level: GL, layout: New([(0, None), (1, None)]), vector_size: None }], false), Standard(MemVec([3, 10, 9, 12])))
cc 22b7db818ddac5cbd1630fef59b20fd8365eeb4175e9e9aca3434ac48a4427d5 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 5], dtypes: [Uint8, Uint8] }, [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], false)
cc 87891db03d9d54a00d967dd862e2fe82d9acb400adfb40d87f56a7112580b3d7 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [1], dtypes: [Uint32, Uint32] }, [TensorSpecAux { contig: 1, aligned: false, level: L1, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: Layout([(0, Dynamic)]), vector_size: Some(8) }], false)
cc bc675e92836ac61a6151abb6314876b5cfe1ffe62bdd5863d77918fb1492372f # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [7, 7, 3, 7], dtypes: [Uint16, Uint16] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 4, 1, 31])))
cc f26a266ef38af1ce6df02a2bcce5874b9ed7a50f8ab357b5513064e338fda302 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [6, 6, 1, 4, 2, 4, 1], dtypes: [Sint32, Sint32, Uint8] }, [TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: Some(16) }, TensorSpecAux { contig: 4, aligned: false, level: L1, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], true)
cc 493104ffc7f1308099674e6e06738ea5c4d84df39bef6e30aa024c8746426017 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [7, 6, 1, 6, 5, 6, 5], dtypes: [Sint16, Sint16, Sint16] }, [TensorSpecAux { contig: 3, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic), (0, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: L1, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 2, 14, 11])))
cc 9876aa14b176a12fdb3de65acc1818c48d7bb640e7a1391ce42968013f162311 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 5, 8], dtypes: [Uint8, Sint32, Bfloat16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 3, 5], dtypes: [Sint32, Uint32, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: Some(4) }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], serial_only: true }, Standard(MemVec([5, 0, 15, 2])))
cc 67e2884237381a67877d481f57f9c2b2046f73b3f8fd9020f38833caac8ebb65 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [6], dtypes: [Uint32, Sint32] }, PrimitiveBasics { typ: Move, spec_shape: [6], dtypes: [Sint8, Uint32] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([0, 0, 8, 16])))
cc 6701523102082fb8981f83dc32520d1909a039bd20e9162d3bbbb6b3a5e01e7e # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [6, 2, 6], dtypes: [Uint16, Float32, Uint16] }, PrimitiveBasics { typ: Move, spec_shape: [6, 2], dtypes: [Bfloat16, Uint16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [6, 7, 2], dtypes: [Float32, Sint8, Bfloat16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: Some(8) }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (0, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([1, 10, 5, 2])))
cc e7b8259de255280f06feb4a1bf8b60218272f437cc116a79c650797187ba8ce6 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [4, 8], dtypes: [Uint8, Uint32] }, PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [4, 6, 8], dtypes: [Sint16, Sint16, Uint8] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [4, 6, 6], dtypes: [Sint32, Sint8, Sint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], serial_only: true }, Standard(MemVec([5, 9, 5, 21])))
cc 0b5f0fadf95c0b9b5e7436cf546f956326e3b007841943f804dcda5277a54d95 # shrinks to spec_type = DivideVecScalarInPlace { scan_dim: 0 }
cc 1227dc11ca18908a4f7aa6f4c135f6770cba0578978f342a419a5d6f83c62444 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Max { dim: 3, accum: true }, spec_shape: [5, 1, 7, 1], dtypes: [Sint16, Uint8] }, PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 3, accum: false }, spec_shape: [5, 1, 7, 3], dtypes: [Sint16, Sint32, Sint16] }, PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 2 }, spec_shape: [5, 1, 7, 3], dtypes: [Sint16, Sint16, Sint16, Sint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(16) }], serial_only: true }, Standard(MemVec([6, 9, 12, 0])))
cc 21f2c898cb0962019956ad0dfe8e314993e6596a54a98aa5d6932021d9cd2308 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Broadcast { dim: 3 }, spec_shape: [1, 1, 7, 7], dtypes: [Float32, Uint8] }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 4, 11, 30])))
cc 2df018778307f0a349a1d97c45b57c8e585235d0b454ab4c7f6f75736176ee48 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominatorAndMax { scan_dim: 2 }, spec_shape: [1, 1, 2, 1], dtypes: [Uint8, Uint8, Uint8] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], false), Standard(MemVec([0, 4, 6, 13])))
cc 3ed56a9899358e10d10937a29c485ad4ad4744222f19417cd7f794f43f19559b # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [8, 1, 4, 4, 5, 2, 1], dtypes: [Sint8, Uint8, Sint16] }, PrimitiveBasics { typ: DivideVecScalar { scan_dim: 2 }, spec_shape: [8, 4, 4, 5], dtypes: [Sint8, Sint32, Sint8] }], operand_auxes: [TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([0, 6, 0, 0])))
cc 4261331366dfc30987742bda3ccdb12e9a402fa3c1c8c3987ebaba85a28f5675 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Broadcast { dim: 1 }, spec_shape: [1, 4], dtypes: [Uint8, Sint32] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], true), Standard(MemVec([4, 8, 13, 31])))
cc 5bc3d556640c8488cef8a88cfbe599bcc6a011fdebc31db47f2d1d0c0a9f4120 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: OnePrefix, spec_shape: [1, 1], dtypes: [Sint16, Uint16] }, [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 10, 12, 3])))
cc 67d0c762bc989877e8707d02211facf1bfec6417eb1c7324d15898a2573b3e74 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [8, 1, 2, 4, 7, 1, 2], dtypes: [Uint8, Sint8, Uint8] }, PrimitiveBasics { typ: DivideVecScalar { scan_dim: 2 }, spec_shape: [8, 2, 4, 7], dtypes: [Uint32, Sint32, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(16) }], serial_only: false }, Standard(MemVec([0, 5, 0, 0])))
cc 730f085a0289b024f7a16c9dcc7f496ef71c57104894bd0a412b4fcbdc0c0ec7 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: OnePrefix, spec_shape: [2], dtypes: [Sint32, Uint32] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(0, Dynamic), (0, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([3, 10, 3, 27])))
cc 8dc9b002c2985331b3533970c8a6f7e3f0aeeb18a9269816d59c72805b6e04fb # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [7, 1, 3, 2, 3, 2, 3], dtypes: [Sint8, Sint16, Uint8] }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([2, 11, 14, 0])))
cc 9ff8d21158e0d8e12026c39e60f6eb8209f48d9b1d937dff3602e73a109501a1 # shrinks to logical_spec = Compose { components: [PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 4, 3], dtypes: [Uint32, Bfloat16, Float32] }, PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 0 }, spec_shape: [1, 4], dtypes: [Uint32, Uint32, Uint32, Uint32] }, PrimitiveBasics { typ: DivideVecScalarInPlace { scan_dim: 0 }, spec_shape: [8, 4], dtypes: [Uint32, Uint32] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], serial_only: true }
cc bc3d0aea49a05531711133d2da735ebecc28d47f90b2dbcaeda7fab889f91783 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [8, 4, 6, 1, 1, 1, 1], dtypes: [Sint32, Uint8, Uint8] }, [TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([5, 9, 13, 2])))
cc def7e5d52cddb9cc6290a96d0754b23a696f1abee9e6bc2fb8f29f8f79427649 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 1, 4, 2], dtypes: [Uint8, Uint8] }, [TensorSpecAux { contig: 3, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], true), Standard(MemVec([7, 11, 16, 31])))
cc e3c904b48ab47e115c3476c9f6111f070b51a7f54fa2465ec8619e2a365536de # shrinks to basics = PrimitiveBasics { typ: OnePrefix, spec_shape: [1], dtypes: [Uint8, Uint8] }
cc ebc4fdae166fc8624f91cd4b5a5e09536e916ebceb0ac24b5753fb6a204d9363 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [8, 1, 3, 2, 1, 1, 1], dtypes: [Sint32, Sint32, Bfloat16] }, PrimitiveBasics { typ: Move, spec_shape: [8, 3, 2, 1], dtypes: [Float32, Sint32] }], operand_auxes: [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], serial_only: false }, Standard(MemVec([7, 11, 0, 0])))
cc e680b6e084083d70711e50e8f8be2632c910b0fad7df6f04ebb046209b4be270 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [6, 8, 1], dtypes: [Uint16, Bfloat16] }, PrimitiveBasics { typ: Move, spec_shape: [6, 8, 1], dtypes: [Uint8, Uint16] }, PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 1 }, spec_shape: [6, 8, 1], dtypes: [Uint8, Uint8, Uint8, Uint8] }], operand_auxes: [TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: Some(8) }], serial_only: false }, Standard(MemVec([4, 9, 0, 0])))
cc c3667c6b826c59a649e19de795bd8c517f1c9fdbf6bc88e2c36881d04383a4ee # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [4, 1, 6, 4, 1, 1, 1], dtypes: [Uint16, Uint8, Bfloat16] }, PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [4, 6, 8, 4, 1, 1, 1], dtypes: [Sint16, Uint32, Uint16] }], operand_auxes: [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], serial_only: false }, Standard(MemVec([4, 10, 0, 0])))
cc 347da66a4db072d39cff10a4cf7cf332bf0d57c2d3af7868ee228e56bbc282ea # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [6, 2, 8, 1, 1, 1, 1], dtypes: [Sint16, Uint16, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], true), Standard(MemVec([5, 3, 1, 0])))
cc da02f937c5b81b9e9bc5686bcb93e826408edc0f234f86f28eccfad798864251 # shrinks to logical_spec = Compose { components: [PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 0 }, spec_shape: [8, 6, 1, 1], dtypes: [Uint16, Uint8, Uint8, Sint16] }, PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [8, 6, 8, 1, 1, 2, 7], dtypes: [Float32, Float32, Uint16] }, PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 2, accum: false }, spec_shape: [8, 8, 8, 1], dtypes: [Uint8, Sint16, Float32] }], operand_auxes: [TensorSpecAux { aligned: true, level: RF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)], contig: 3 }, vector_size: None }, TensorSpecAux { aligned: false, level: GL, layout: Layout { dims: [(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)], contig: 4 }, vector_size: None }, TensorSpecAux { aligned: true, level: RF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (1, Packed(8))], contig: 0 }, vector_size: None }, TensorSpecAux { aligned: false, level: RF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (0, Packed(2))], contig: 5 }, vector_size: None }, TensorSpecAux { aligned: true, level: L1, layout: Layout { dims: [(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)], contig: 3 }, vector_size: None }, TensorSpecAux { aligned: false, level: VRF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (0, Packed(2))], contig: 3 }, vector_size: Some(16) }], serial_only: false }
cc 8d68dac5ff113ac5597be9c6ca70de742211795749c8509c7b1ee4d89aaaa5d8 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [1, 7, 5, 3], dtypes: [Float32, Uint8] }, PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [1, 7, 3, 5, 3, 2, 8], dtypes: [Uint32, Uint16, Float32] }], operand_auxes: [TensorSpecAux { aligned: false, level: RF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)], contig: 0 }, vector_size: None }, TensorSpecAux { aligned: false, level: RF, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)], contig: 0 }, vector_size: None }, TensorSpecAux { aligned: false, level: L1, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)], contig: 0 }, vector_size: None }], serial_only: false }, Standard(MemVec([8, 10, 8192*, 0*])))
cc 9cb32b3c7912e6a7119d51dc097d2dd23c97e0c7e251a541946003813fbb5a6f # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [1, 1, 7, 3], dtypes: [Sint16, Uint16, Sint16] }, [TensorSpecAux { aligned: false, level: L1, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic)], contig: 0 }, vector_size: None }, TensorSpecAux { aligned: false, level: L1, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic)], contig: 0 }, vector_size: None }, TensorSpecAux { aligned: false, level: L1, layout: Layout { dims: [(0, Dynamic), (1, Dynamic), (2, Dynamic)], contig: 0 }, vector_size: None }], true), Standard(MemVec([5, 9, 2048*, 0*])))
