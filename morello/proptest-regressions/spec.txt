# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 621b28a0003170be9222da23c41c090ec5e74a300b151cd6975afe99a0695d6e # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [1, 4, 3, 14, 4, 14, 4], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Standard { dim_order: [0, 1, 2, 3] }, vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Packed { dim_count: 4, strip_dim: 0, strip_size: 2 }, vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Standard { dim_order: [0, 1, 2, 3] }, vector_size: None }], false), Standard(MemVec([64, 1024, 32768, 1073741824])))
cc d5426c7bbcebdcc94c7ac335e850051746c583d940c99fee06766bd804c98a59 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 5, 3], dtype: Uint8 }, [TensorSpecAux { contig: 3, aligned: true, level: GL, layout: Standard { dim_order: [0, 1, 2] }, vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: GL, layout: Packed { dim_count: 3, strip_dim: 1, strip_size: 4 }, vector_size: None }], false), Standard(MemVec([5, 4, 5, 19])))
cc 447224448efccd63b4b9d2fe07ba7933ec0062b1ca30eba898c6466eda8376d7 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 3], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None), (0, Some(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(1, None), (0, None)]), vector_size: None }], false)
cc 77094c43ccba12f5f0a16f0597c2abf9a1a0d063b6b636cdfc5d0c4b1f8b00f4 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [2, 3, 1], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(1, None), (0, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: New([(0, None), (1, None)]), vector_size: None }], false), Standard(MemVec([4, 4, 9, 4])))
cc 086206919c1e3b52e6509d8ae98732239cc8975ce1bb7eb326331724186bcca5 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 1], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }], true)
cc 1776df2ad05dea8e23b1cd294aceb31a18345f5be19b7a66e11e90818a90ec08 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [3, 5, 2, 8, 4, 8, 4], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: New([(0, None), (2, None), (3, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (2, Some(2))]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None)]), vector_size: None }], false), Standard(MemVec([5, 9, 2, 24])))
cc ca9e4ca2bd3626671393aaff4300d5d86fd65e73f6c080aa2b27c90f387a9906 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [6, 2, 3, 4, 6, 1, 2], dtype: Uint32 }, [TensorSpecAux { contig: 4, aligned: false, level: GL, layout: New([(0, None), (2, None), (3, None), (1, None), (3, Some(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: VRF, layout: New([(0, None), (2, None), (3, None), (1, None), (0, Some(2))]), vector_size: Some(16) }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: New([(0, None), (2, None), (3, None), (1, None), (0, Some(2))]), vector_size: Some(16) }], true), Standard(MemVec([4, 1, 11, 19])))
cc 738ff6c91fce386119abb1ccef46e4f7058a7f331660231e41a37b6d2dfe6115 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 4, 1], dtype: Uint32 }, [TensorSpecAux { contig: 4, aligned: true, level: RF, layout: New([(0, None), (1, None), (2, None), (0, Some(3))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (1, Some(2))]), vector_size: None }], false), Standard(MemVec([4, 1, 1, 7])))
cc b6c7d507517cf04edab95cde53e6436709ccde7ff0a139a76a92753c08a5c0c1 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [2, 8, 1], dtype: Uint8 }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: New([(0, None), (1, None)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: New([(0, None), (1, None), (0, Some(2))]), vector_size: None }], false)
cc 85ecfac179f4e3e8d334f2d8d820224a4620d1ec7ad2bdf338306efde4636009 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [7, 4, 1, 3, 1, 3, 1], dtype: Uint32 }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: New([(0, None), (1, None), (2, None), (3, None)]), vector_size: None }, TensorSpecAux { contig: 5, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (2, Some(3))]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: GL, layout: New([(0, None), (1, None), (2, None), (3, None), (0, Some(7))]), vector_size: None }], false)
cc 92f95d4f0b88593df4096072665f0ada65b9d6ba7dcdf7527ffbd07785af5605 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 2], dtypes: [Uint16] }, [TensorSpecAux { contig: 2, aligned: true, level: GL, layout: New([(0, None), (1, None)]), vector_size: None }], false), Standard(MemVec([3, 10, 9, 12])))
cc 22b7db818ddac5cbd1630fef59b20fd8365eeb4175e9e9aca3434ac48a4427d5 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 5], dtypes: [Uint8, Uint8] }, [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], false)
cc 87891db03d9d54a00d967dd862e2fe82d9acb400adfb40d87f56a7112580b3d7 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Move, spec_shape: [1], dtypes: [Uint32, Uint32] }, [TensorSpecAux { contig: 1, aligned: false, level: L1, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: VRF, layout: Layout([(0, Dynamic)]), vector_size: Some(8) }], false)
cc bc675e92836ac61a6151abb6314876b5cfe1ffe62bdd5863d77918fb1492372f # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [7, 7, 3, 7], dtypes: [Uint16, Uint16] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 4, 1, 31])))
cc f26a266ef38af1ce6df02a2bcce5874b9ed7a50f8ab357b5513064e338fda302 # shrinks to logical_spec = Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [6, 6, 1, 4, 2, 4, 1], dtypes: [Sint32, Sint32, Uint8] }, [TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: Some(16) }, TensorSpecAux { contig: 4, aligned: false, level: L1, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], true)
cc 493104ffc7f1308099674e6e06738ea5c4d84df39bef6e30aa024c8746426017 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [7, 6, 1, 6, 5, 6, 5], dtypes: [Sint16, Sint16, Sint16] }, [TensorSpecAux { contig: 3, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic), (0, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: L1, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 2, 14, 11])))
cc 9876aa14b176a12fdb3de65acc1818c48d7bb640e7a1391ce42968013f162311 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 5, 8], dtypes: [Uint8, Sint32, Bfloat16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 3, 5], dtypes: [Sint32, Uint32, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: Some(4) }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], serial_only: true }, Standard(MemVec([5, 0, 15, 2])))
cc 67e2884237381a67877d481f57f9c2b2046f73b3f8fd9020f38833caac8ebb65 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [6], dtypes: [Uint32, Sint32] }, PrimitiveBasics { typ: Move, spec_shape: [6], dtypes: [Sint8, Uint32] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([0, 0, 8, 16])))
cc 6701523102082fb8981f83dc32520d1909a039bd20e9162d3bbbb6b3a5e01e7e # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [6, 2, 6], dtypes: [Uint16, Float32, Uint16] }, PrimitiveBasics { typ: Move, spec_shape: [6, 2], dtypes: [Bfloat16, Uint16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [6, 7, 2], dtypes: [Float32, Sint8, Bfloat16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: Some(8) }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (0, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([1, 10, 5, 2])))
cc e7b8259de255280f06feb4a1bf8b60218272f437cc116a79c650797187ba8ce6 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [4, 8], dtypes: [Uint8, Uint32] }, PrimitiveBasics { typ: Matmul { accum: true }, spec_shape: [4, 6, 8], dtypes: [Sint16, Sint16, Uint8] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [4, 6, 6], dtypes: [Sint32, Sint8, Sint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], serial_only: true }, Standard(MemVec([5, 9, 5, 21])))
cc 0b5f0fadf95c0b9b5e7436cf546f956326e3b007841943f804dcda5277a54d95 # shrinks to spec_type = DivideVecScalarInPlace { scan_dim: 0 }
cc 1227dc11ca18908a4f7aa6f4c135f6770cba0578978f342a419a5d6f83c62444 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Max { dim: 3, accum: true }, spec_shape: [5, 1, 7, 1], dtypes: [Sint16, Uint8] }, PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 3, accum: false }, spec_shape: [5, 1, 7, 3], dtypes: [Sint16, Sint32, Sint16] }, PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 2 }, spec_shape: [5, 1, 7, 3], dtypes: [Sint16, Sint16, Sint16, Sint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(16) }], serial_only: true }, Standard(MemVec([6, 9, 12, 0])))
cc 21f2c898cb0962019956ad0dfe8e314993e6596a54a98aa5d6932021d9cd2308 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Broadcast { dim: 3 }, spec_shape: [1, 1, 7, 7], dtypes: [Float32, Uint8] }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 4, 11, 30])))
cc 2df018778307f0a349a1d97c45b57c8e585235d0b454ab4c7f6f75736176ee48 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominatorAndMax { scan_dim: 2 }, spec_shape: [1, 1, 2, 1], dtypes: [Uint8, Uint8, Uint8] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], false), Standard(MemVec([0, 4, 6, 13])))
cc 3ed56a9899358e10d10937a29c485ad4ad4744222f19417cd7f794f43f19559b # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [8, 1, 4, 4, 5, 2, 1], dtypes: [Sint8, Uint8, Sint16] }, PrimitiveBasics { typ: DivideVecScalar { scan_dim: 2 }, spec_shape: [8, 4, 4, 5], dtypes: [Sint8, Sint32, Sint8] }], operand_auxes: [TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([0, 6, 0, 0])))
cc 4261331366dfc30987742bda3ccdb12e9a402fa3c1c8c3987ebaba85a28f5675 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Broadcast { dim: 1 }, spec_shape: [1, 4], dtypes: [Uint8, Sint32] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic), (1, Packed(2))]), vector_size: None }], true), Standard(MemVec([4, 8, 13, 31])))
cc 67d0c762bc989877e8707d02211facf1bfec6417eb1c7324d15898a2573b3e74 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [8, 1, 2, 4, 7, 1, 2], dtypes: [Uint8, Sint8, Uint8] }, PrimitiveBasics { typ: DivideVecScalar { scan_dim: 2 }, spec_shape: [8, 2, 4, 7], dtypes: [Uint32, Sint32, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(16) }], serial_only: false }, Standard(MemVec([0, 5, 0, 0])))
cc 9ff8d21158e0d8e12026c39e60f6eb8209f48d9b1d937dff3602e73a109501a1 # shrinks to logical_spec = Compose { components: [PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 4, 3], dtypes: [Uint32, Bfloat16, Float32] }, PrimitiveBasics { typ: SoftmaxComplete { scan_dim: 0 }, spec_shape: [1, 4], dtypes: [Uint32, Uint32, Uint32, Uint32] }, PrimitiveBasics { typ: DivideVecScalarInPlace { scan_dim: 0 }, spec_shape: [8, 4], dtypes: [Uint32, Uint32] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], serial_only: true }
cc bc3d0aea49a05531711133d2da735ebecc28d47f90b2dbcaeda7fab889f91783 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [8, 4, 6, 1, 1, 1, 1], dtypes: [Sint32, Uint8, Uint8] }, [TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (1, Packed(2))]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([5, 9, 13, 2])))
cc def7e5d52cddb9cc6290a96d0754b23a696f1abee9e6bc2fb8f29f8f79427649 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [3, 1, 4, 2], dtypes: [Uint8, Uint8] }, [TensorSpecAux { contig: 3, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(8) }], true), Standard(MemVec([7, 11, 16, 31])))
