# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 5db1da8814022601244836ccdba0649b89bb457eda069d896c48fe0ba61782cb # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 1, 2], dtypes: [Sint16, Uint8, Sint32] }, [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([5, 11, 0, 0])))
cc c02c1c345bf38f6cb53c761ae0511b90d30d38c2d5b8ace4236804b76e3f02de # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 2], dtypes: [Sint16] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 3, 0, 0])))
cc 38ea03ae586a529bca1c509ddea493de4048b4e41cac56c00f8713602e50cd0e # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [4, 5], dtypes: [Bfloat16, Bfloat16] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], false), Standard(MemVec([0, 0, 4, 22])))
cc 2deaa3e1d7211487ea42ddf911030a38cdc9b1f8d6ce44c14398058119e2ecc0 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [3, 4, 2, 1, 1, 1, 1], dtypes: [Sint16, Sint16, Uint32] }, [TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 5, 11, 11])))
cc 01f3576b7683931614a66e4ddefcb84607f3eff8e72ec469db96d773eaab67ef # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [7, 4, 7], dtypes: [Uint8, Uint8, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: VRF, layout: Layout([(1, Dynamic), (0, Dynamic), (0, Packed(2))]), vector_size: Some(8) }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], true), Standard(MemVec([6, 9, 8, 0])))
cc c84b7c43a1b47ae34dac2e682fd8477bab88a3253f0b51ae3bf73ec3b2844355 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [3, 2], dtypes: [Uint16, Bfloat16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [3, 3, 2], dtypes: [Uint32, Sint32, Uint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([7, 0, 2, 0])))
cc 25f2cf570bddc47cb91507c1086dbd658092d5adc31b90399324f81745729ef7 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Softmax { reduction_dim: 2, accum: false }, spec_shape: [1, 8, 5], dtypes: [Sint32, Float32] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: Some(4) }], true), Standard(MemVec([0, 7, 0, 0])))
cc a2a6627a7bcee4ae7771436a6cf15c8e9bb063da8ebb84e073d42ac195b1addc # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [2, 1, 2, 4, 8, 1, 2], dtypes: [Uint8, Uint32, Bfloat16] }, PrimitiveBasics { typ: Softmax { reduction_dim: 3, accum: false }, spec_shape: [2, 2, 4, 1, 8], dtypes: [Sint8, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (4, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([7, 7, 0, 0])))
cc b59550dec7a9220957ef7ffedc570b00544f0097efc173a789ad0eb5ea6454b2 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [7, 3, 7, 1, 1, 1, 1], dtypes: [Sint8, Uint8, Uint16] }, PrimitiveBasics { typ: Move, spec_shape: [7, 7, 1, 1], dtypes: [Uint16, Sint8] }, PrimitiveBasics { typ: Max { dim: 2, accum: false }, spec_shape: [7, 7, 5, 1], dtypes: [Uint16, Uint16] }], operand_auxes: [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([1, 10, 5, 15])))
cc 015b451470fb3dbdbbb5cbef8b27883b6c293a253acb84dcee3c8d28e47b4b92 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominatorAndUnscaled { scan_dim: 0, accum: true }, spec_shape: [5, 3], dtypes: [Sint32, Sint8, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: Some(8) }], false), Standard(MemVec([0, 7, 9, 0])))
cc 3728ec1ba104be0c7a59902168de682e684314ea2589599ccf4c19edfe737333 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Max { dim: 1, accum: false }, spec_shape: [4, 7, 7, 1], dtypes: [Sint16, Float32] }, PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 3, accum: false }, spec_shape: [4, 7, 7, 5], dtypes: [Sint32, Bfloat16, Sint16] }, PrimitiveBasics { typ: DivideVec, spec_shape: [4, 7, 7, 5], dtypes: [Uint32, Bfloat16, Sint32] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: Some(4) }], serial_only: true }, Standard(MemVec([1, 4, 10, 0])))
cc e656e32b8d8b8f7e7f5c0a57b382419448ef90ebb2edfb6dff92ed100b610e4b # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [2, 6, 6], dtypes: [Uint32, Sint16, Sint8] }, [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: Some(4) }, TensorSpecAux { contig: 2, aligned: true, level: GL, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], false), Standard(MemVec([7, 8, 1, 0])))
cc f26c2c058f17fa286ba1b14b8072eb819c7cac4eb7ac7a2585a0b06943647bb3 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [7, 1, 7, 7, 3, 4, 2], dtypes: [Uint8, Uint32, Uint16] }, PrimitiveBasics { typ: Broadcast { dim: 2 }, spec_shape: [7, 7, 7, 3], dtypes: [Uint32, Uint8] }], operand_auxes: [TensorSpecAux { contig: 4, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 4, aligned: true, level: RF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([6, 5, 3, 0])))
