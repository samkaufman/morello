# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 5db1da8814022601244836ccdba0649b89bb457eda069d896c48fe0ba61782cb # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 1, 2], dtypes: [Sint16, Uint8, Sint32] }, [TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([5, 11, 0, 0])))
cc c02c1c345bf38f6cb53c761ae0511b90d30d38c2d5b8ace4236804b76e3f02de # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Zero, spec_shape: [1, 2], dtypes: [Sint16] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 3, 0, 0])))
cc 38ea03ae586a529bca1c509ddea493de4048b4e41cac56c00f8713602e50cd0e # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Move, spec_shape: [4, 5], dtypes: [Bfloat16, Bfloat16] }, [TensorSpecAux { contig: 1, aligned: false, level: GL, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: RF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], false), Standard(MemVec([0, 0, 4, 22])))
cc 2deaa3e1d7211487ea42ddf911030a38cdc9b1f8d6ce44c14398058119e2ecc0 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [3, 4, 2, 1, 1, 1, 1], dtypes: [Sint16, Sint16, Uint32] }, [TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 2, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], false), Standard(MemVec([4, 5, 11, 11])))
cc 01f3576b7683931614a66e4ddefcb84607f3eff8e72ec469db96d773eaab67ef # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [7, 4, 7], dtypes: [Uint8, Uint8, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: VRF, layout: Layout([(1, Dynamic), (0, Dynamic), (0, Packed(2))]), vector_size: Some(8) }, TensorSpecAux { contig: 0, aligned: true, level: L1, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: None }], true), Standard(MemVec([6, 9, 8, 0])))
cc c84b7c43a1b47ae34dac2e682fd8477bab88a3253f0b51ae3bf73ec3b2844355 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [3, 2], dtypes: [Uint16, Bfloat16] }, PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [3, 3, 2], dtypes: [Uint32, Sint32, Uint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }], serial_only: false }, Standard(MemVec([7, 0, 2, 0])))
cc 25f2cf570bddc47cb91507c1086dbd658092d5adc31b90399324f81745729ef7 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Softmax { reduction_dim: 2, accum: false }, spec_shape: [1, 8, 5], dtypes: [Sint32, Float32] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 1, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (1, Packed(2))]), vector_size: Some(4) }], true), Standard(MemVec([0, 7, 0, 0])))
cc a2a6627a7bcee4ae7771436a6cf15c8e9bb063da8ebb84e073d42ac195b1addc # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: true }, spec_shape: [2, 1, 2, 4, 8, 1, 2], dtypes: [Uint8, Uint32, Bfloat16] }, PrimitiveBasics { typ: Softmax { reduction_dim: 3, accum: false }, spec_shape: [2, 2, 4, 1, 8], dtypes: [Sint8, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (4, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], serial_only: true }, Standard(MemVec([7, 7, 0, 0])))
