# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 1289ffaedc9bb0c5dbec00d4f88ad00304c6efbf1af1945f4a514a0babd544a9 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Move, spec_shape: [1, 1, 5], dtypes: [Uint8, Sint8] }, PrimitiveBasics { typ: Move, spec_shape: [1, 1, 5], dtypes: [Sint16, Uint8] }, PrimitiveBasics { typ: Max { dim: 1, accum: false }, spec_shape: [1, 1, 5], dtypes: [Float32, Sint16] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: Some(16) }], serial_only: false }, Standard(MemVec([6, 5, 0, 0])))
cc 70e66313b253b886e3d5082c5a3b4b4702875e182aaff049a3e72ba8529582ad # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 2, accum: false }, spec_shape: [2, 4, 4, 5], dtypes: [Sint8, Sint8, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: GL, layout: Layout([(2, Dynamic), (3, Dynamic), (1, Dynamic), (0, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: GL, layout: Layout([(2, Dynamic), (3, Dynamic), (1, Dynamic), (0, Dynamic)]), vector_size: None }], true), Standard(MemVec([6, 10, 11, 18])))
cc 6596bef7941ba7c5e31ac129acdcdd670b21c4fad1a7bf30e4f1ffc1b82aa572 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominator { scan_dim: 3, accum: false }, spec_shape: [1, 4, 6, 2, 2], dtypes: [Uint8, Sint8, Bfloat16] }, [TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (4, Dynamic)]), vector_size: Some(32) }, TensorSpecAux { contig: 5, aligned: true, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (4, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: L1, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic), (4, Dynamic)]), vector_size: None }], true), Standard(MemVec([3, 9, 2, 20])))
cc 6777c726f045c48d287a95dcce0cc67f7ec338c03d29a94ac4ef89b7aab75a52 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Matmul { accum: false }, spec_shape: [1, 2, 8], dtypes: [Uint8, Uint8, Uint32] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(1, Dynamic), (0, Dynamic)]), vector_size: Some(16) }, TensorSpecAux { contig: 2, aligned: true, level: VRF, layout: Layout([(0, Dynamic), (1, Dynamic)]), vector_size: Some(8) }], false), Standard(MemVec([0, 6, 0, 0])))
cc 85cadeb9a4eef705225141cc45812521929a20826494299510843d5e04266b17 # shrinks to spec = Spec(Compose { components: [PrimitiveBasics { typ: Conv { accum: false }, spec_shape: [5, 4, 5, 1, 4, 1, 1], dtypes: [Bfloat16, Uint8, Sint8] }, PrimitiveBasics { typ: Move, spec_shape: [5, 5, 1, 4], dtypes: [Uint8, Bfloat16] }, PrimitiveBasics { typ: Softmax { scan_dim: 2 }, spec_shape: [5, 5, 1, 4], dtypes: [Uint8, Uint8] }], operand_auxes: [TensorSpecAux { contig: 0, aligned: false, level: L1, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: GL, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: VRF, layout: Layout([(0, Dynamic), (2, Dynamic), (3, Dynamic), (1, Dynamic)]), vector_size: Some(16) }], serial_only: true }, Standard(MemVec([1, 9, 9, 18])))
cc 0f9a614ef4161cfcdb9cec81077e2e3076e674cea46cd5fdb1959e9ad5c6af72 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: SoftmaxDenominatorAndMax { scan_dim: 1, accum: false }, spec_shape: [1, 2, 7], dtypes: [Sint8, Sint8, Sint8] }, [TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 0, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: true, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }], true), Standard(MemVec([2, 2, 0, 0])))
cc fd8b1a4abcfca70ad8299fa41353fa835fc296c63dbcdca89cb50d0f0e030af9 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Max { dim: 2, accum: false }, spec_shape: [1, 1, 1, 1], dtypes: [Uint8, Sint8] }, [TensorSpecAux { contig: 4, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 4, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic), (3, Dynamic)]), vector_size: None }], true), Standard(MemVec([6, 4, 0, 0])))
cc 6a116c1400d9334356d8b3e0e2396efb669e30c814e6ae6f196445742e162361 # shrinks to spec = Spec(Primitive(PrimitiveBasics { typ: Max { dim: 1, accum: false }, spec_shape: [1, 1, 1], dtypes: [Uint8, Float32] }, [TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }, TensorSpecAux { contig: 3, aligned: false, level: RF, layout: Layout([(0, Dynamic), (1, Dynamic), (2, Dynamic)]), vector_size: None }], true), Standard(MemVec([4, 0, 0, 0])))
